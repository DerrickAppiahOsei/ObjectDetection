{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:02:04.623209: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 16:02:04.656526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 16:02:04.656554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 16:02:04.657576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 16:02:04.663421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 16:02:05.329199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-11 16:02:06.429104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21851 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Configure Keras to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    images = hdf.get('images')\n",
    "    boxes = hdf.get('boxes')\n",
    "    images = np.array(images)\n",
    "    boxes = np.array(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_normalized = (images+1)/9.26 # Normalize images and add noise\n",
    "\n",
    "\n",
    "# Normalize bounding boxes\n",
    "normalized_boxes = boxes / [1,64,64,64,64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:02:13.277217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21851 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (64, 64, 1)\n",
    "num_classes = 280\n",
    "num_coordinates = 4\n",
    "\n",
    "images_np = image_normalized\n",
    "#images_np = tf.expand_dims(images_np, axis=-1)\n",
    "probabilities = np.array(normalized_boxes[:, :,:-4])\n",
    "probabilities = tf.expand_dims(probabilities, axis=1)\n",
    "boxes_np = np.array(normalized_boxes[:, :, 1:])\n",
    "boxes_np = tf.expand_dims(boxes_np, axis=1)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "\n",
    "# Assuming dataset has 10,000 examples and we want an 80/20 split\n",
    "total_items = 10000\n",
    "train_size = int(total_items * 0.8)\n",
    "val_size = total_items - train_size\n",
    "\n",
    "# Splitting the dataset\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_size,reshuffle_each_iteration=True)\n",
    "train_dataset = train_dataset.batch(256)\n",
    "val_dataset = val_dataset.batch(256) \n",
    "\n",
    "x_input = layers.Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)  \n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)  # size: 32x32\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)  # size: 32x32\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)  # size: 16x16\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)  # size: 16x16\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) # size: 8x8x\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) # size: 8x8x\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) # size: 8x8x\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) # size: 8x8x\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# Bounding box output\n",
    "x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)  # Consider adjusting based on performance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer= optimizer, loss= {'x_prob_reshape': tf.keras.losses.BinaryCrossentropy(), 'x_boxes_reshape':tf.keras.losses.MeanSquaredError()}, metrics={'x_prob_reshape': 'accuracy'} )\n",
    "num_epochs = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:02:18.720652: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-03-11 16:02:18.809856: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-11 16:02:20.655401: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-11 16:02:21.747746: I external/local_xla/xla/service/service.cc:168] XLA service 0x7c17dc444fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-11 16:02:21.747789: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-11 16:02:21.760963: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710187341.903562  558514 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 36s 371ms/step - loss: 0.8196 - x_prob_reshape_loss: 0.6067 - x_boxes_reshape_loss: 0.2129 - x_prob_reshape_accuracy: 0.6765 - val_loss: 0.8773 - val_x_prob_reshape_loss: 0.7560 - val_x_boxes_reshape_loss: 0.1213 - val_x_prob_reshape_accuracy: 0.2935\n",
      "Epoch 2/2000\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.4805 - x_prob_reshape_loss: 0.3282 - x_boxes_reshape_loss: 0.1523 - x_prob_reshape_accuracy: 0.8900 - val_loss: 1.0770 - val_x_prob_reshape_loss: 0.9308 - val_x_boxes_reshape_loss: 0.1462 - val_x_prob_reshape_accuracy: 0.3018\n",
      "Epoch 3/2000\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.2732 - x_prob_reshape_loss: 0.1900 - x_boxes_reshape_loss: 0.0831 - x_prob_reshape_accuracy: 0.9530 - val_loss: 1.3856 - val_x_prob_reshape_loss: 1.1900 - val_x_boxes_reshape_loss: 0.1956 - val_x_prob_reshape_accuracy: 0.3213\n",
      "Epoch 4/2000\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.2001 - x_prob_reshape_loss: 0.1430 - x_boxes_reshape_loss: 0.0571 - x_prob_reshape_accuracy: 0.9645 - val_loss: 1.6773 - val_x_prob_reshape_loss: 1.4421 - val_x_boxes_reshape_loss: 0.2352 - val_x_prob_reshape_accuracy: 0.3360\n",
      "Epoch 5/2000\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.1680 - x_prob_reshape_loss: 0.1192 - x_boxes_reshape_loss: 0.0489 - x_prob_reshape_accuracy: 0.9702 - val_loss: 1.8716 - val_x_prob_reshape_loss: 1.6117 - val_x_boxes_reshape_loss: 0.2599 - val_x_prob_reshape_accuracy: 0.3497\n",
      "Epoch 6/2000\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.1512 - x_prob_reshape_loss: 0.1059 - x_boxes_reshape_loss: 0.0453 - x_prob_reshape_accuracy: 0.9722 - val_loss: 1.9219 - val_x_prob_reshape_loss: 1.6487 - val_x_boxes_reshape_loss: 0.2732 - val_x_prob_reshape_accuracy: 0.3699\n",
      "Epoch 7/2000\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.1378 - x_prob_reshape_loss: 0.0950 - x_boxes_reshape_loss: 0.0428 - x_prob_reshape_accuracy: 0.9745 - val_loss: 1.7927 - val_x_prob_reshape_loss: 1.5183 - val_x_boxes_reshape_loss: 0.2744 - val_x_prob_reshape_accuracy: 0.4066\n",
      "Epoch 8/2000\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.1271 - x_prob_reshape_loss: 0.0859 - x_boxes_reshape_loss: 0.0412 - x_prob_reshape_accuracy: 0.9774 - val_loss: 1.5321 - val_x_prob_reshape_loss: 1.2727 - val_x_boxes_reshape_loss: 0.2594 - val_x_prob_reshape_accuracy: 0.4538\n",
      "Epoch 9/2000\n",
      "21/32 [==================>...........] - ETA: 1s - loss: 0.1214 - x_prob_reshape_loss: 0.0809 - x_boxes_reshape_loss: 0.0404 - x_prob_reshape_accuracy: 0.9781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you've already prepared train_dataset and val_dataset as shown previously\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training data\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Add other callbacks here as needed, such as ModelCheckpoint or ReduceLROnPlateau\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/electron/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming you've already prepared train_dataset and val_dataset as shown previously\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train_dataset,  # Training data\n",
    "    epochs=num_epochs,  # Number of epochs\n",
    "    validation_data=val_dataset  # Validation data\n",
    "    \n",
    "        # Add other callbacks here as needed, such as ModelCheckpoint or ReduceLROnPlateau\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model5zeroes18000epochs.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = tf.keras.models.load_model('model5zeroes.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 280, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs,targets = next(iter(train_dataset))\n",
    "output = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 280, 4), dtype=float64, numpy=\n",
       "array([[[0.1875  , 0.125   , 0.1875  , 0.140625],\n",
       "        [0.703125, 0.96875 , 0.71875 , 0.96875 ],\n",
       "        [0.375   , 0.03125 , 0.390625, 0.046875],\n",
       "        ...,\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      ]]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['x_boxes_reshape'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.50287485, 0.50324047, 0.5162776 , 0.51210386],\n",
       "        [0.49115506, 0.5044168 , 0.47959256, 0.49766976],\n",
       "        [0.4916473 , 0.5037574 , 0.501271  , 0.5008709 ],\n",
       "        ...,\n",
       "        [0.5047096 , 0.50420105, 0.4847019 , 0.4976152 ],\n",
       "        [0.47998655, 0.5145917 , 0.48303685, 0.49814385],\n",
       "        [0.5002177 , 0.5049797 , 0.516437  , 0.49200475]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.3538769832865899\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "r = np.random.randint(0,100)\n",
    "tensor1 = tf.constant(targets['x_boxes_reshape'], dtype=tf.float64)\n",
    "\n",
    "tensor2 = tf.constant(output[1], dtype=tf.float32)\n",
    "\n",
    "\n",
    "tensor2 = tf.cast(tensor2, tf.float64)\n",
    "\n",
    "\n",
    "mse_loss_fn =  tf.keras.losses.MeanSquaredError()\n",
    "mse_loss = mse_loss_fn(tensor1, tensor2)\n",
    "\n",
    "print(\"MSE Loss:\", mse_loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_bounding_boxes(image, probability_vector, bounding_box_coordinates, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Visualizes bounding boxes on an image based on a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - probability_vector: A 1D tensor representing the probabilities associated with bounding boxes.\n",
    "    - bounding_box_coordinates: A 2D tensor representing bounding box coordinates.\n",
    "    - threshold: Probability threshold for visualization.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with bounding boxes).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    prob_vector_np = probability_vector\n",
    "    bbox_coordinates_np = bounding_box_coordinates\n",
    "   # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(\"Bounding Box Visualization\")\n",
    "\n",
    "    # Plot bounding boxes based on probability threshold\n",
    "    for i in range(len(prob_vector_np)):\n",
    "        prob = prob_vector_np[i]\n",
    "        bbox = bbox_coordinates_np[i]\n",
    "        if prob > threshold:\n",
    "            # Denormalize bounding box coordinates if necessary\n",
    "            denormalized_bbox = bbox  # Modify if normalization was applied during training\n",
    "            y1, x1, y2, x2 = denormalized_bbox\n",
    "            plt.plot([x1, x2, x2, x1, x1],[y1, y1, y2, y2, y1],\n",
    "                     \n",
    "                     color='r', linewidth=2, label='Bounding Box')\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "t = np.random.randint(0,128)\n",
    "\n",
    "\n",
    "visualize_bounding_boxes(tf.convert_to_tensor(inputs[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(output[1][t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "#visualize_bounding_boxes(tf.convert_to_tensor(image_normalized[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(boxes_np[t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
