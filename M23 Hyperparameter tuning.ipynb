{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 13:32:49.586678: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 13:32:49.625123: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 13:32:49.625153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 13:32:49.626216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 13:32:49.632925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 13:32:50.283428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-26 13:32:51.495173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21907 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "\n",
    "# Configure Keras to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# import random\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"MyFirstComputerVision\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 10,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # simulate training\n",
    "# epochs = 10\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2, epochs):\n",
    "#     acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "#     loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    images = hdf.get('images')\n",
    "    boxes = hdf.get('boxes')\n",
    "    images = np.array(images)\n",
    "    boxes = np.array(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_normalized = (images+1e-9)/9.26 # Normalize images and add noise\n",
    "\n",
    "\n",
    "# Normalize bounding boxes\n",
    "normalized_boxes = boxes / [1,64,64,64,64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 13:33:17.969081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21907 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (64, 64, 1)\n",
    "num_classes = 280\n",
    "num_coordinates = 4\n",
    "\n",
    "images_np = image_normalized\n",
    "#images_np = tf.expand_dims(images_np, axis=-1)\n",
    "probabilities = np.array(normalized_boxes[:, :,:-4])\n",
    "probabilities = tf.expand_dims(probabilities, axis=1)\n",
    "boxes_np = np.array(normalized_boxes[:, :, 1:])\n",
    "boxes_np = tf.expand_dims(boxes_np, axis=1)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "dataset = dataset.shuffle(buffer_size=10000,reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(128)\n",
    "\n",
    "# # Assuming dataset has 10,000 examples and we want an 80/20 split\n",
    "# total_items = 10000\n",
    "# train_size = int(total_items * 0.6)\n",
    "# val_size = total_items - train_size\n",
    "\n",
    "# # Splitting the dataset\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# val_dataset = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_size,reshuffle_each_iteration=True)\n",
    "# train_dataset = train_dataset.batch(64)\n",
    "# val_dataset = val_dataset.batch(64) \n",
    "\n",
    "# start a new wandb run to track this script\n",
    "\n",
    "\n",
    "\n",
    "x_input = layers.Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    " \n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) # size: 8x8x\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# Bounding box output\n",
    "x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)  # Consider adjusting based on performance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer= optimizer, loss= {'x_prob_reshape': tf.keras.losses.BinaryCrossentropy(), 'x_boxes_reshape':tf.keras.losses.MeanSquaredError()}, metrics={'x_prob_reshape': 'accuracy'} )\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'fc_layer_size': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "    'dropout': {\n",
    "          'values': [0.3, 0.4, 0.5]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 1}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values',\n",
      "                               'max': 256,\n",
      "                               'min': 32,\n",
      "                               'q': 8},\n",
      "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
      "                'epochs': {'value': 1},\n",
      "                'fc_layer_size': {'values': [128, 256, 512]},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 0bt130jx\n",
      "Sweep URL: https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"M23 Hyperparameter Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"MyFirstComputerVision\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 3e-5,\n",
    "#     \"architecture\": \"model\",\n",
    "#     \"dataset\": \"dataset\",\n",
    "#     \"epochs\": \"num_epochs\",\n",
    "#     }\n",
    "# )\n",
    "# # simulate training\n",
    "\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2,num_epochs):\n",
    "#     acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "#     loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('M11overfittedmodel3variant.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 13:50:47.516518: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-26 13:50:47.602849: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-26 13:50:48.622823: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-26 13:50:49.512318: I external/local_xla/xla/service/service.cc:168] XLA service 0x7cecd44557e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-26 13:50:49.512356: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-26 13:50:49.525351: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711475449.672995   55592 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 21s 93ms/step - loss: 0.5040 - x_prob_reshape_loss: 0.3691 - x_boxes_reshape_loss: 0.1349 - x_prob_reshape_accuracy: 0.8537\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 6s 71ms/step - loss: 0.2388 - x_prob_reshape_loss: 0.1736 - x_boxes_reshape_loss: 0.0651 - x_prob_reshape_accuracy: 0.9482\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.1882 - x_prob_reshape_loss: 0.1345 - x_boxes_reshape_loss: 0.0537 - x_prob_reshape_accuracy: 0.9566\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 6s 71ms/step - loss: 0.1692 - x_prob_reshape_loss: 0.1191 - x_boxes_reshape_loss: 0.0501 - x_prob_reshape_accuracy: 0.9581\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 6s 70ms/step - loss: 0.1578 - x_prob_reshape_loss: 0.1096 - x_boxes_reshape_loss: 0.0483 - x_prob_reshape_accuracy: 0.9592\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 6s 71ms/step - loss: 0.1443 - x_prob_reshape_loss: 0.0975 - x_boxes_reshape_loss: 0.0468 - x_prob_reshape_accuracy: 0.9643\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.1393 - x_prob_reshape_loss: 0.0932 - x_boxes_reshape_loss: 0.0460 - x_prob_reshape_accuracy: 0.9646\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.1319 - x_prob_reshape_loss: 0.0867 - x_boxes_reshape_loss: 0.0452 - x_prob_reshape_accuracy: 0.9667\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 6s 73ms/step - loss: 0.1283 - x_prob_reshape_loss: 0.0836 - x_boxes_reshape_loss: 0.0447 - x_prob_reshape_accuracy: 0.9674\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 6s 73ms/step - loss: 0.1240 - x_prob_reshape_loss: 0.0798 - x_boxes_reshape_loss: 0.0442 - x_prob_reshape_accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model.fit(\n",
    "#     dataset,\n",
    "#     epochs=num_epochs \n",
    "   \n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: omkow137 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06272054278490398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240326_141623-omkow137</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/omkow137/workspace' target=\"_blank\">likely-sweep-4</a></strong> to <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/omkow137/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/omkow137/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-4</strong> at: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/omkow137/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/omkow137/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240326_141623-omkow137/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run omkow137 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run omkow137 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model(config)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: au1nfahk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.024934070612601156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240326_141636-au1nfahk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/au1nfahk/workspace' target=\"_blank\">confused-sweep-5</a></strong> to <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/au1nfahk/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/au1nfahk/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-5</strong> at: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/au1nfahk/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/au1nfahk/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240326_141636-au1nfahk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run au1nfahk errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run au1nfahk errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model(config)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wbaw45hk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07946818898599503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240326_141647-wbaw45hk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/wbaw45hk/workspace' target=\"_blank\">dazzling-sweep-6</a></strong> to <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/sweeps/0bt130jx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/wbaw45hk/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/wbaw45hk/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-sweep-6</strong> at: <a href='https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/wbaw45hk/workspace' target=\"_blank\">https://wandb.ai/alphanium/M23%20Hyperparameter%20Tuning/runs/wbaw45hk/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240326_141647-wbaw45hk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run wbaw45hk errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "    model = model(config)\n",
      "UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run wbaw45hk errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_55414/2795004664.py\", line 6, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = model(config)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m UnboundLocalError: local variable 'model' referenced before assignment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init() as run:\n",
    "        config = run.config\n",
    "        # Build, train, and evaluate your model\n",
    "        model = model(config)\n",
    "        model.fit(dataset, epochs=num_epochs)\n",
    "        # Optionally log model performance and save the model\n",
    "\n",
    "wandb.agent(sweep_id, train, count=12)  # Run the sweep agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('M11overfittedmodel3variant.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('M11overfittedmodel3variant.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 280, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "\n",
    "# # Assuming dataset has 10,000 examples and we want an 80/20 split\n",
    "# total_items = 10000\n",
    "# train_size = int(total_items * 0.6)\n",
    "# # val_size = total_items - train_size\n",
    "\n",
    "# # Splitting the dataset\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# # val_dataset = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "# # train_dataset = train_dataset.shuffle(buffer_size=train_size,reshuffle_each_iteration=True)\n",
    "# train_dataset = train_dataset.batch(6000)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "dataset = dataset.batch(10000)\n",
    "inputs,targets = next(iter(dataset))\n",
    "output = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 280, 4), dtype=float64, numpy=\n",
       "array([[[0.734375, 0.015625, 0.734375, 0.03125 ],\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        ...,\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      ]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['x_boxes_reshape'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.24306941e-01, 3.01006213e-02, 7.41804957e-01, 3.33228447e-02],\n",
       "        [2.24880949e-02, 7.51386629e-03, 2.32093632e-02, 7.64035154e-03],\n",
       "        [4.27702442e-03, 6.26132824e-03, 4.65806713e-03, 6.90292520e-03],\n",
       "        ...,\n",
       "        [2.88477138e-04, 1.39197495e-04, 1.47837753e-04, 1.58194220e-04],\n",
       "        [1.42245786e-04, 2.08800062e-04, 1.84095348e-04, 1.41638870e-04],\n",
       "        [1.16996292e-04, 1.13774906e-04, 1.76820322e-04, 1.51523607e-04]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 1.3558886642682864e-07\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "r = np.random.randint(0,100)\n",
    "tensor1 = tf.constant(targets['x_prob_reshape'], dtype=tf.float64)\n",
    "\n",
    "tensor2 = tf.constant(output[0], dtype=tf.float32)\n",
    "\n",
    "\n",
    "tensor2 = tf.cast(tensor2, tf.float64)\n",
    "\n",
    "\n",
    "mse_loss_fn =  tf.keras.losses.BinaryCrossentropy()\n",
    "mse_loss = mse_loss_fn(tensor1, tensor2)\n",
    "\n",
    "print(\"MSE Loss:\", mse_loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     34\u001b[0m             plt\u001b[38;5;241m.\u001b[39mplot([x1, x2, x2, x1, x1],[y1, y1, y2, y2, y1],\n\u001b[1;32m     35\u001b[0m                      \n\u001b[1;32m     36\u001b[0m                      color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBounding Box\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 48\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     51\u001b[0m visualize_bounding_boxes(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs[t]), probabilities\u001b[38;5;241m.\u001b[39mnumpy()[t]\u001b[38;5;241m.\u001b[39msqueeze(), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output[\u001b[38;5;241m1\u001b[39m][t,\u001b[38;5;241m0\u001b[39m,:,:])\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m]) \u001b[38;5;66;03m##myprediction\u001b[39;00m\n\u001b[1;32m     52\u001b[0m visualize_bounding_boxes(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(image_normalized[t]), probabilities\u001b[38;5;241m.\u001b[39mnumpy()[t]\u001b[38;5;241m.\u001b[39msqueeze(), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(boxes_np[t,\u001b[38;5;241m0\u001b[39m,:,:])\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m]) \u001b[38;5;66;03m##myprediction\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize_bounding_boxes(image, probability_vector, bounding_box_coordinates, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Visualizes bounding boxes on an image based on a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - probability_vector: A 1D tensor representing the probabilities associated with bounding boxes.\n",
    "    - bounding_box_coordinates: A 2D tensor representing bounding box coordinates.\n",
    "    - threshold: Probability threshold for visualization.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with bounding boxes).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    prob_vector_np = probability_vector\n",
    "    bbox_coordinates_np = bounding_box_coordinates\n",
    "   # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(\"Bounding Box Visualization\")\n",
    "\n",
    "    # Plot bounding boxes based on probability threshold\n",
    "    for i in range(len(prob_vector_np)):\n",
    "        prob = prob_vector_np[i]\n",
    "        bbox = bbox_coordinates_np[i]\n",
    "        if prob > threshold:\n",
    "            # Denormalize bounding box coordinates if necessary\n",
    "            denormalized_bbox = bbox  # Modify if normalization was applied during training\n",
    "            y1, x1, y2, x2 = denormalized_bbox\n",
    "            plt.plot([x1, x2, x2, x1, x1],[y1, y1, y2, y2, y1],\n",
    "                     \n",
    "                     color='r', linewidth=2, label='Bounding Box')\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "t = np.random.randint(0,100)\n",
    "\n",
    "\n",
    "visualize_bounding_boxes(tf.convert_to_tensor(inputs[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(output[1][t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "visualize_bounding_boxes(tf.convert_to_tensor(image_normalized[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(boxes_np[t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
