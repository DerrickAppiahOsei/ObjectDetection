{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 4, False Positives: 0, True Negatives: 8, False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, pred_thresh, diff_thresh):\n",
    "    predicted_classes = (y_pred > pred_thresh).astype(int)  # Shape: (n_samples, n_features)\n",
    "    abs_diff = np.abs(y_pred - y_true)\n",
    "    is_close_enough = abs_diff <= diff_thresh  # Shape: (n_samples, n_features)\n",
    "\n",
    "    # TP and FP calculation remains unchanged\n",
    "    close_enough_all = np.all(is_close_enough, axis=1)[:, np.newaxis]  # Make it (n_samples, 1)\n",
    "    TP = np.logical_and(predicted_classes == 1, close_enough_all)\n",
    "    FP = np.logical_and(predicted_classes == 1, ~close_enough_all)\n",
    "    TN = predicted_classes == 0\n",
    "\n",
    "    # Adjusted FN calculation\n",
    "    # We create a mask where each prediction is checked coordinate-wise\n",
    "    FN_mask = np.logical_and(predicted_classes == 0, y_true > pred_thresh)\n",
    "    FN = np.sum(FN_mask)  # This will sum true values across all dimensions\n",
    "\n",
    "    return np.sum(TP), np.sum(FP), np.sum(TN), FN\n",
    "# def evaluate_predictions(y_true, y_pred, pred_thresh, diff_thresh):\n",
    "#     predicted_classes = (y_pred > pred_thresh).astype(int)\n",
    "#     abs_diff = np.abs(y_pred - y_true)\n",
    "#     is_close_enough = abs_diff <= diff_thresh\n",
    "\n",
    "#     close_enough_all = np.all(is_close_enough, axis=1)[:, np.newaxis]  # Shape (n_samples, 1)\n",
    "#     TP = np.sum(np.logical_and(predicted_classes == 1, close_enough_all))\n",
    "#     FP = np.sum(np.logical_and(predicted_classes == 1, ~close_enough_all))\n",
    "#     TN = np.sum(predicted_classes == 0)\n",
    "\n",
    "#     # Create a mask that checks if any of the ground truth values exceed the prediction threshold\n",
    "#     # Expand this result to match dimensions with predicted_classes for element-wise comparison\n",
    "#     FN_condition = (np.any(y_true > pred_thresh, axis=1)[:, np.newaxis]).astype(int)\n",
    "#     FN = np.sum(np.logical_and(predicted_classes == 0, FN_condition))\n",
    "\n",
    "#     return TP, FP, TN, FN\n",
    "\n",
    "# Then you can use the function as before with your example data.\n",
    "\n",
    "\n",
    "\n",
    "# Example data (the same as before)\n",
    "predictions = np.array([\n",
    "    [0.6, 0.6, 0.4, 0.4],  # Close to the ground truth\n",
    "    [0.1, 0.1, 0.9, 0.9],  # One coordinate significantly off\n",
    "    [0.2, 0.2, 0.2, 0.2]   # Should not be detected (low values, classified as negative)\n",
    "])\n",
    "ground_truths = np.array([\n",
    "    [0.58, 0.62, 0.38, 0.42],  # Ground truth for the first prediction\n",
    "    [0.1, 0.2, 0.9, 0.8],      # Ground truth for the second prediction\n",
    "    [0.0, 0.0, 0.0, 0.0]       # Ground truth for the third prediction (no box)\n",
    "])\n",
    "prediction_thresholds = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "difference_thresholds = np.array([0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "# Evaluate the predictions\n",
    "TP, FP, TN, FN = evaluate_predictions(ground_truths, predictions, prediction_thresholds, difference_thresholds)\n",
    "print(f\"True Positives: {TP}, False Positives: {FP}, True Negatives: {TN}, False Negatives: {FN}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
