{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 13:57:01.748624: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 13:57:01.780781: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-02 13:57:01.780806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-02 13:57:01.781670: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-02 13:57:01.787147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 13:57:02.486839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-02 13:57:03.828285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21945 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "\n",
    "# Configure Keras to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Ensure wandb is installed: pip install wandb\n",
    "# Initialize your W&B project before running the script\n",
    "\n",
    "# Dataset loading and preparation\n",
    "def load_and_prepare_dataset(batch_size):\n",
    "    with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "        images = np.array(hdf.get('images'))\n",
    "        boxes = np.array(hdf.get('boxes'))\n",
    "    \n",
    "\n",
    "    image_normalized = (images + 1e-9) / 9.26\n",
    "    normalized_boxes = boxes / [1, 64, 64, 64, 64]\n",
    "\n",
    "    images_np = image_normalized\n",
    "    probabilities = np.array(normalized_boxes[:, :, :-4])\n",
    "    probabilities = tf.expand_dims(probabilities, axis=1)\n",
    "    boxes_np = np.array(normalized_boxes[:, :, 1:])\n",
    "    boxes_np = tf.expand_dims(boxes_np, axis=1)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_boxes_reshape': boxes_np}))\n",
    "    dataset = dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Model building\n",
    "def build_model():\n",
    "    input_shape = (64, 64, 1)\n",
    "    num_classes = 280\n",
    "    num_coordinates = 4\n",
    "\n",
    "    x_input = layers.Input(shape=input_shape)\n",
    "    #Layer 1\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "    \n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 2\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 3\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 4\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    #Layer 5\n",
    "    x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "    \n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "    x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "    x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "    x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "    model = models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "    return model\n",
    "\n",
    "# Optimizer selection\n",
    "def select_optimizer(optimizer_name, learning_rate):\n",
    "    if optimizer_name == 'adam':\n",
    "        return optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        return optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer specified.\")\n",
    "\n",
    "# Training function with sweep\n",
    "def train_with_sweep():\n",
    "    \n",
    "    with wandb.init():\n",
    "        config = wandb.config\n",
    "        # # config.run.id\n",
    "        # print(wandb.run.id)\n",
    "        # print(wandb.run.name)\n",
    "        dataset = load_and_prepare_dataset(config.batch_size)\n",
    "        model = build_model()\n",
    "        \n",
    "        optimizer = select_optimizer(config.optimizer, config.learning_rate)\n",
    "        model.compile(optimizer=optimizer, \n",
    "                      loss={'x_prob_reshape': 'binary_crossentropy', 'x_boxes_reshape': 'mean_squared_error'}, \n",
    "                      metrics={'x_prob_reshape': 'accuracy'})\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(dataset, epochs=config.epochs, callbacks=[wandb.keras.WandbCallback()])\n",
    "        model.save(f'{wandb.run.name}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        }\n",
    "    \n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 11}\n",
    "    })\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        'values': [32, 64, 256]\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 0h9lxtih\n",
      "Sweep URL: https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s393sb1f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0823033353181903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240402_142322-s393sb1f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/s393sb1f/workspace' target=\"_blank\">glad-sweep-1</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/s393sb1f/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/s393sb1f/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      " 6/40 [===>..........................] - ETA: 4s - loss: 2.3448 - x_prob_reshape_loss: 2.1385 - x_boxes_reshape_loss: 0.2062 - x_prob_reshape_accuracy: 0.7078WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0500s vs `on_train_batch_end` time: 0.0714s). Check your callbacks.\n",
      "40/40 [==============================] - 8s 132ms/step - loss: 1.0897 - x_prob_reshape_loss: 0.9548 - x_boxes_reshape_loss: 0.1349 - x_prob_reshape_accuracy: 0.7584\n",
      "Epoch 2/11\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.5583 - x_prob_reshape_loss: 0.4723 - x_boxes_reshape_loss: 0.0860 - x_prob_reshape_accuracy: 0.7698\n",
      "Epoch 3/11\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.5213 - x_prob_reshape_loss: 0.4449 - x_boxes_reshape_loss: 0.0764 - x_prob_reshape_accuracy: 0.7788\n",
      "Epoch 4/11\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.5150 - x_prob_reshape_loss: 0.4409 - x_boxes_reshape_loss: 0.0740 - x_prob_reshape_accuracy: 0.7810\n",
      "Epoch 5/11\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.5233 - x_prob_reshape_loss: 0.4469 - x_boxes_reshape_loss: 0.0764 - x_prob_reshape_accuracy: 0.7771\n",
      "Epoch 6/11\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.5152 - x_prob_reshape_loss: 0.4411 - x_boxes_reshape_loss: 0.0742 - x_prob_reshape_accuracy: 0.7803\n",
      "Epoch 7/11\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.5134 - x_prob_reshape_loss: 0.4402 - x_boxes_reshape_loss: 0.0732 - x_prob_reshape_accuracy: 0.7814\n",
      "Epoch 8/11\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.5093 - x_prob_reshape_loss: 0.4375 - x_boxes_reshape_loss: 0.0718 - x_prob_reshape_accuracy: 0.7831\n",
      "Epoch 9/11\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.5106 - x_prob_reshape_loss: 0.4385 - x_boxes_reshape_loss: 0.0721 - x_prob_reshape_accuracy: 0.7820\n",
      "Epoch 10/11\n",
      "40/40 [==============================] - 5s 128ms/step - loss: 0.5118 - x_prob_reshape_loss: 0.4391 - x_boxes_reshape_loss: 0.0727 - x_prob_reshape_accuracy: 0.7821\n",
      "Epoch 11/11\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.5101 - x_prob_reshape_loss: 0.4380 - x_boxes_reshape_loss: 0.0721 - x_prob_reshape_accuracy: 0.7829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>█▃▂▁▂▁▁▁▁▁▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁▄▇▇▆▇█████</td></tr><tr><td>x_prob_reshape_loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.51007</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.07209</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.78286</td></tr><tr><td>x_prob_reshape_loss</td><td>0.43798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-1</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/s393sb1f/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/s393sb1f/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_142322-s393sb1f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iytcyopz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08136128429895936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240402_142439-iytcyopz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/iytcyopz/workspace' target=\"_blank\">likely-sweep-2</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/iytcyopz/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/iytcyopz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "313/313 [==============================] - 10s 26ms/step - loss: 0.2133 - x_prob_reshape_loss: 0.1461 - x_boxes_reshape_loss: 0.0673 - x_prob_reshape_accuracy: 0.9401\n",
      "Epoch 2/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1485 - x_prob_reshape_loss: 0.0981 - x_boxes_reshape_loss: 0.0503 - x_prob_reshape_accuracy: 0.9578\n",
      "Epoch 3/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1461 - x_prob_reshape_loss: 0.0966 - x_boxes_reshape_loss: 0.0495 - x_prob_reshape_accuracy: 0.9583\n",
      "Epoch 4/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1408 - x_prob_reshape_loss: 0.0925 - x_boxes_reshape_loss: 0.0483 - x_prob_reshape_accuracy: 0.9602\n",
      "Epoch 5/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1364 - x_prob_reshape_loss: 0.0887 - x_boxes_reshape_loss: 0.0477 - x_prob_reshape_accuracy: 0.9618\n",
      "Epoch 6/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1253 - x_prob_reshape_loss: 0.0786 - x_boxes_reshape_loss: 0.0467 - x_prob_reshape_accuracy: 0.9658\n",
      "Epoch 7/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1206 - x_prob_reshape_loss: 0.0740 - x_boxes_reshape_loss: 0.0466 - x_prob_reshape_accuracy: 0.9678\n",
      "Epoch 8/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1244 - x_prob_reshape_loss: 0.0777 - x_boxes_reshape_loss: 0.0467 - x_prob_reshape_accuracy: 0.9665\n",
      "Epoch 9/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1305 - x_prob_reshape_loss: 0.0834 - x_boxes_reshape_loss: 0.0471 - x_prob_reshape_accuracy: 0.9642\n",
      "Epoch 10/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1177 - x_prob_reshape_loss: 0.0714 - x_boxes_reshape_loss: 0.0462 - x_prob_reshape_accuracy: 0.9693\n",
      "Epoch 11/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.1216 - x_prob_reshape_loss: 0.0750 - x_boxes_reshape_loss: 0.0466 - x_prob_reshape_accuracy: 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▃▃▃▂▂▁▁▂▁▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>█▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁▅▅▆▆▇█▇▇██</td></tr><tr><td>x_prob_reshape_loss</td><td>█▄▃▃▃▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.12161</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.04661</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.96767</td></tr><tr><td>x_prob_reshape_loss</td><td>0.07501</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-2</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/iytcyopz/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/iytcyopz/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_142439-iytcyopz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q8in8y8w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04841650567961406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240402_142626-q8in8y8w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/q8in8y8w/workspace' target=\"_blank\">upbeat-sweep-3</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/q8in8y8w/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/q8in8y8w/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "313/313 [==============================] - 11s 26ms/step - loss: 0.5363 - x_prob_reshape_loss: 0.4540 - x_boxes_reshape_loss: 0.0823 - x_prob_reshape_accuracy: 0.8001\n",
      "Epoch 2/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.4870 - x_prob_reshape_loss: 0.4163 - x_boxes_reshape_loss: 0.0707 - x_prob_reshape_accuracy: 0.7941\n",
      "Epoch 3/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5065 - x_prob_reshape_loss: 0.4341 - x_boxes_reshape_loss: 0.0724 - x_prob_reshape_accuracy: 0.7834\n",
      "Epoch 4/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5062 - x_prob_reshape_loss: 0.4340 - x_boxes_reshape_loss: 0.0722 - x_prob_reshape_accuracy: 0.7831\n",
      "Epoch 5/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5070 - x_prob_reshape_loss: 0.4340 - x_boxes_reshape_loss: 0.0730 - x_prob_reshape_accuracy: 0.7836\n",
      "Epoch 6/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5094 - x_prob_reshape_loss: 0.4357 - x_boxes_reshape_loss: 0.0737 - x_prob_reshape_accuracy: 0.7823\n",
      "Epoch 7/11\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.5125 - x_prob_reshape_loss: 0.4374 - x_boxes_reshape_loss: 0.0752 - x_prob_reshape_accuracy: 0.7814\n",
      "Epoch 8/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5108 - x_prob_reshape_loss: 0.4364 - x_boxes_reshape_loss: 0.0743 - x_prob_reshape_accuracy: 0.7818\n",
      "Epoch 9/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5175 - x_prob_reshape_loss: 0.4404 - x_boxes_reshape_loss: 0.0771 - x_prob_reshape_accuracy: 0.7812\n",
      "Epoch 10/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5145 - x_prob_reshape_loss: 0.4392 - x_boxes_reshape_loss: 0.0754 - x_prob_reshape_accuracy: 0.7810\n",
      "Epoch 11/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5131 - x_prob_reshape_loss: 0.4391 - x_boxes_reshape_loss: 0.0740 - x_prob_reshape_accuracy: 0.7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▁▄▄▄▄▅▄▅▅▅</td></tr><tr><td>x_boxes_reshape_loss</td><td>█▁▂▂▂▃▄▃▅▄▃</td></tr><tr><td>x_prob_reshape_accuracy</td><td>█▆▂▂▂▂▁▁▁▁▁</td></tr><tr><td>x_prob_reshape_loss</td><td>█▁▄▄▄▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.51308</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.07402</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.78081</td></tr><tr><td>x_prob_reshape_loss</td><td>0.43906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-3</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/q8in8y8w/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/q8in8y8w/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_142626-q8in8y8w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x44tyx07 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07042099330959255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240402_142813-x44tyx07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/x44tyx07/workspace' target=\"_blank\">pretty-sweep-4</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/x44tyx07/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/x44tyx07/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "313/313 [==============================] - 11s 26ms/step - loss: 0.6198 - x_prob_reshape_loss: 0.5351 - x_boxes_reshape_loss: 0.0847 - x_prob_reshape_accuracy: 0.7873\n",
      "Epoch 2/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.4998 - x_prob_reshape_loss: 0.4279 - x_boxes_reshape_loss: 0.0720 - x_prob_reshape_accuracy: 0.7898\n",
      "Epoch 3/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5079 - x_prob_reshape_loss: 0.4352 - x_boxes_reshape_loss: 0.0727 - x_prob_reshape_accuracy: 0.7833\n",
      "Epoch 4/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5151 - x_prob_reshape_loss: 0.4397 - x_boxes_reshape_loss: 0.0754 - x_prob_reshape_accuracy: 0.7797\n",
      "Epoch 5/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5198 - x_prob_reshape_loss: 0.4408 - x_boxes_reshape_loss: 0.0790 - x_prob_reshape_accuracy: 0.7796\n",
      "Epoch 6/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5193 - x_prob_reshape_loss: 0.4408 - x_boxes_reshape_loss: 0.0785 - x_prob_reshape_accuracy: 0.7793\n",
      "Epoch 7/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5223 - x_prob_reshape_loss: 0.4426 - x_boxes_reshape_loss: 0.0797 - x_prob_reshape_accuracy: 0.7784\n",
      "Epoch 8/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5243 - x_prob_reshape_loss: 0.4426 - x_boxes_reshape_loss: 0.0817 - x_prob_reshape_accuracy: 0.7780\n",
      "Epoch 9/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5225 - x_prob_reshape_loss: 0.4415 - x_boxes_reshape_loss: 0.0810 - x_prob_reshape_accuracy: 0.7792\n",
      "Epoch 10/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.5252 - x_prob_reshape_loss: 0.4430 - x_boxes_reshape_loss: 0.0822 - x_prob_reshape_accuracy: 0.7784\n",
      "Epoch 11/11\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.8424 - x_prob_reshape_loss: 0.7231 - x_boxes_reshape_loss: 0.1192 - x_prob_reshape_accuracy: 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>▃▁▁▁▁▁▁▂▁▂█</td></tr><tr><td>x_boxes_reshape_loss</td><td>▃▁▁▂▂▂▂▂▂▃█</td></tr><tr><td>x_prob_reshape_accuracy</td><td>██▇▆▆▆▆▆▆▆▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▄▁▁▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.84238</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.11924</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.74757</td></tr><tr><td>x_prob_reshape_loss</td><td>0.72314</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-sweep-4</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/x44tyx07/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/x44tyx07/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_142813-x44tyx07/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nws1arm2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.043814348862147634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240402_143000-nws1arm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/nws1arm2/workspace' target=\"_blank\">magic-sweep-5</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/sweeps/0h9lxtih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/nws1arm2/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/nws1arm2/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      " 6/40 [===>..........................] - ETA: 4s - loss: 0.8369 - x_prob_reshape_loss: 0.6298 - x_boxes_reshape_loss: 0.2071 - x_prob_reshape_accuracy: 0.6599WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0486s vs `on_train_batch_end` time: 0.0726s). Check your callbacks.\n",
      "40/40 [==============================] - 7s 134ms/step - loss: 0.5301 - x_prob_reshape_loss: 0.3678 - x_boxes_reshape_loss: 0.1624 - x_prob_reshape_accuracy: 0.8475\n",
      "Epoch 2/11\n",
      "40/40 [==============================] - 5s 134ms/step - loss: 0.2409 - x_prob_reshape_loss: 0.1519 - x_boxes_reshape_loss: 0.0890 - x_prob_reshape_accuracy: 0.9515\n",
      "Epoch 3/11\n",
      "40/40 [==============================] - 5s 134ms/step - loss: 0.2018 - x_prob_reshape_loss: 0.1350 - x_boxes_reshape_loss: 0.0669 - x_prob_reshape_accuracy: 0.9502\n",
      "Epoch 4/11\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.1846 - x_prob_reshape_loss: 0.1257 - x_boxes_reshape_loss: 0.0588 - x_prob_reshape_accuracy: 0.9525\n",
      "Epoch 5/11\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.1620 - x_prob_reshape_loss: 0.1064 - x_boxes_reshape_loss: 0.0555 - x_prob_reshape_accuracy: 0.9609\n",
      "Epoch 6/11\n",
      "40/40 [==============================] - 5s 132ms/step - loss: 0.1576 - x_prob_reshape_loss: 0.1036 - x_boxes_reshape_loss: 0.0540 - x_prob_reshape_accuracy: 0.9599\n",
      "Epoch 7/11\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.1638 - x_prob_reshape_loss: 0.1105 - x_boxes_reshape_loss: 0.0532 - x_prob_reshape_accuracy: 0.9555\n",
      "Epoch 8/11\n",
      "40/40 [==============================] - 5s 132ms/step - loss: 0.1449 - x_prob_reshape_loss: 0.0931 - x_boxes_reshape_loss: 0.0518 - x_prob_reshape_accuracy: 0.9647\n",
      "Epoch 9/11\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.1476 - x_prob_reshape_loss: 0.0964 - x_boxes_reshape_loss: 0.0513 - x_prob_reshape_accuracy: 0.9611\n",
      "Epoch 10/11\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.1382 - x_prob_reshape_loss: 0.0880 - x_boxes_reshape_loss: 0.0502 - x_prob_reshape_accuracy: 0.9656\n",
      "Epoch 11/11\n",
      "40/40 [==============================] - 5s 132ms/step - loss: 0.1339 - x_prob_reshape_loss: 0.0841 - x_boxes_reshape_loss: 0.0498 - x_prob_reshape_accuracy: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3-learning/anaconda3/envs/tiny_yolo/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▂▁▁▁▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>█▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁▇▇▇██▇████</td></tr><tr><td>x_prob_reshape_loss</td><td>█▃▂▂▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.13389</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.04981</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.96753</td></tr><tr><td>x_prob_reshape_loss</td><td>0.08407</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-sweep-5</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/nws1arm2/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning%20Yichen%20edit%20A2/runs/nws1arm2/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240402_143000-nws1arm2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Working Hyperparameter Tuning Yichen edit A2\")\n",
    "wandb.agent(sweep_id, train_with_sweep, count=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
