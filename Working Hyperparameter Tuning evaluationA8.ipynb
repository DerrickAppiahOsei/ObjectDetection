{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 17:15:45.048505: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-08 17:15:45.080898: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-08 17:15:45.080927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-08 17:15:45.081819: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-08 17:15:45.087082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 17:15:45.722139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-08 17:15:47.061524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21932 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "\n",
    "# Configure Keras to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    images = hdf.get('images')\n",
    "    boxes = hdf.get('boxes')\n",
    "    images = np.array(images)\n",
    "    boxes = np.array(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 17:15:53.344951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21932 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "image_normalized = (images + 1e-9) / 9.26\n",
    "normalized_boxes = boxes / [1, 64, 64, 64, 64]\n",
    "\n",
    "images_np = image_normalized\n",
    "\n",
    "probabilities = np.array(normalized_boxes[:, :, :-4])\n",
    "probabilities = tf.expand_dims(probabilities, axis=1)\n",
    "boxes_np = np.array(normalized_boxes[:, :, 1:])\n",
    "boxes_np = tf.expand_dims(boxes_np, axis=1)\n",
    "batch_size = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_boxes_reshape': boxes_np}))\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# total_items = 10000\n",
    "# train_size = int(total_items * 0.6)\n",
    "# val_size = total_items - train_size\n",
    "\n",
    "# # Splitting the dataset\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# val_dataset = dataset.take(val_size)\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=train_size,reshuffle_each_iteration=True)\n",
    "# train_dataset = train_dataset.batch(batch_size)\n",
    "# val_dataset = val_dataset.batch(batch_size) \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "\n",
    "    \n",
    "input_shape = (64,64,1)\n",
    "num_classes = 280\n",
    "num_coordinates = 4\n",
    "\n",
    "x_input = layers.Input(shape=input_shape)\n",
    "#Layer 1\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 2\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 3\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 4\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "#Layer 5\n",
    "x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# Probability output\n",
    "x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "# Bounding box output\n",
    "x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5) \n",
    "model.compile(optimizer= optimizer, loss= {'x_prob_reshape': tf.keras.losses.BinaryCrossentropy(), 'x_boxes_reshape':tf.keras.losses.MeanSquaredError()}, metrics={'x_prob_reshape': 'accuracy'} )\n",
    "num_epochs = 100\n",
    "        \n",
    "#         # Fit the model with both training and validation datasets\n",
    "# model.fit(train_dataset, \n",
    "#                   epochs=num_epochs, \n",
    "#                   validation_data=val_dataset, \n",
    "#                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #Fit the model with both training and validation datasets\n",
    "model.fit(dataset, \n",
    "                  epochs=num_epochs\n",
    "                  \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"/home/m3-learning/Documents/Research Data/Derrick's Object Detection/Models/M11overfittedmodel3variant.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def compute_iou(box1, box2):\n",
    "#     \"\"\"Compute the Intersection Over Union of two bounding boxes.\"\"\"\n",
    "#     # Determine the coordinates of the intersection rectangle\n",
    "#     x_left = max(box1[0], box2[0])\n",
    "#     y_top = max(box1[1], box2[1])\n",
    "#     x_right = min(box1[2], box2[2])\n",
    "#     y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "#     if x_right < x_left or y_bottom < y_top:\n",
    "#         return 0.0\n",
    "\n",
    "#     intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "#     box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "#     box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "#     iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "#     return iou\n",
    "# def precision_recall_at_iou_threshold(predicted_boxes, ground_truth_boxes, iou_threshold=0.2):\n",
    "#     \"\"\"Calculate precision and recall at a given IoU threshold.\"\"\"\n",
    "#     true_positives = 0\n",
    "#     false_positives = 0\n",
    "#     false_negatives = len(ground_truth_boxes)\n",
    "\n",
    "#     for pred_box in predicted_boxes:\n",
    "#         match_found = False\n",
    "#         for gt_box in ground_truth_boxes:\n",
    "#             iou = compute_iou(pred_box, gt_box)\n",
    "#             if iou >= iou_threshold:\n",
    "#                 true_positives += 1\n",
    "#                 false_negatives -= 1\n",
    "#                 match_found = True\n",
    "#                 break  # Assume each gt box can only match with one predicted box\n",
    "#         if not match_found:\n",
    "#             false_positives += 1\n",
    "\n",
    "#     precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "#     recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "#     return precision, recall\n",
    "\n",
    "# def extract_ground_truth_boxes(gt_data):\n",
    "#     \"\"\"\n",
    "#     Extract the ground truth bounding boxes from the ground truth data.\n",
    "\n",
    "#     Parameters:\n",
    "#     - gt_data: The ground truth data for a single image, structured as a numpy array where the first column indicates\n",
    "#                the presence of an object and the next four columns are the bounding box coordinates.\n",
    "\n",
    "#     Returns:\n",
    "#     - A list of bounding boxes where each box is represented as [x_min, y_min, x_max, y_max].\n",
    "#     \"\"\"\n",
    "#     gt_boxes = []\n",
    "#     for row in gt_data:\n",
    "#         # Check if the object is present\n",
    "#         if row[0] == 1.0:\n",
    "#             # Extract the bounding box coordinates\n",
    "#             box = row[1:]\n",
    "#             gt_boxes.append(box)\n",
    "#     return gt_boxes\n",
    "\n",
    "\n",
    "# def extract_boxes(predictions, probability_threshold=0.2):\n",
    "#     \"\"\"\n",
    "#     Extract bounding boxes based on the probability threshold.\n",
    "    \n",
    "#     predictions: A tuple containing two elements; the first is the probability output of the model,\n",
    "#     and the second is the bounding boxes output of the model.\n",
    "#     probability_threshold: Threshold to filter bounding boxes based on their probabilities.\n",
    "    \n",
    "#     Returns a list of extracted bounding boxes that exceed the probability threshold.\n",
    "#     \"\"\"\n",
    "#     prob_predictions, box_predictions = predictions\n",
    "#     extracted_boxes = []\n",
    "    \n",
    "#     # Assuming the shape of prob_predictions is (batch_size, 1, num_classes, 1)\n",
    "#     # and the shape of box_predictions is (batch_size, 1, num_classes, num_coordinates)\n",
    "#     # Adjust indices if your model output structure differs\n",
    "#     for class_index in range(prob_predictions.shape[2]):\n",
    "#         if prob_predictions[0, class_index, 0] >= probability_threshold:\n",
    "#             # Extract and denormalize the bounding box here if necessary\n",
    "#             box = box_predictions[0,  class_index, :]\n",
    "#             extracted_boxes.append(box)  # Convert to numpy array if not already\n",
    "            \n",
    "#     return extracted_boxes\n",
    "\n",
    "# def evaluate_model(model, dataset, iou_threshold=0.2):\n",
    "#     all_precisions = []\n",
    "#     all_recalls = []\n",
    "\n",
    "#     for inputs, targets in dataset:\n",
    "#         output = model.predict(inputs)\n",
    "#         for i in range(len(inputs)):\n",
    "#             # Corrected call to extract_boxes\n",
    "#             pred_boxes = extract_boxes((output[0][i], output[1][i]), probability_threshold=0.2)\n",
    "            \n",
    "#             # Extract ground truth bounding boxes\n",
    "#             gt_boxes = extract_ground_truth_boxes(targets['x_boxes_reshape'][i].numpy().squeeze())\n",
    "            \n",
    "#             # Evaluate precision and recall for the current set of predictions and ground truth\n",
    "#             precision, recall = precision_recall_at_iou_threshold(pred_boxes, gt_boxes, iou_threshold=iou_threshold)\n",
    "#             all_precisions.append(precision)\n",
    "#             all_recalls.append(recall)\n",
    "\n",
    "#     # Compute overall metrics\n",
    "#     mean_precision = np.mean (all_precisions)\n",
    "#     mean_recall = np.mean(all_recalls)\n",
    "#     print(f\"Mean Precision: {mean_precision}, Mean Recall: {mean_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "\n",
    "\n",
    "dataset = dataset.batch(10000)\n",
    "inputs,targets = next(iter(dataset))\n",
    "output = loaded_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute the Intersection Over Union of two bounding boxes.\"\"\"\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "# def compute_iou_values(predicted_boxes, ground_truth_boxes):\n",
    "#     \"\"\"Compute IoU values for each pair of predicted and ground truth boxes.\"\"\"\n",
    "#     iou_values = []\n",
    "\n",
    "#     for pred_box in predicted_boxes:\n",
    "#         best_iou = 0\n",
    "#         for gt_box in ground_truth_boxes:\n",
    "#             iou = compute_iou(pred_box, gt_box)\n",
    "#             if iou > best_iou:\n",
    "#                 best_iou = iou\n",
    "#         if best_iou > 0:\n",
    "#             iou_values.append(best_iou)\n",
    "\n",
    "#     return iou_values\n",
    "\n",
    "\n",
    "def precision_recall_at_iou_threshold(predicted_boxes, ground_truth_boxes, iou_threshold=0.1):\n",
    "    \"\"\"Calculate and print IoU values alongside precision and recall at a given IoU threshold.\"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = len(ground_truth_boxes)\n",
    "    iou_values = []  # Store IoU values for analysis\n",
    "\n",
    "    for pred_box in predicted_boxes:\n",
    "        match_found = False\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            iou = compute_iou(pred_box, gt_box)\n",
    "            if iou > 0:  # Print or store IoU values greater than 0\n",
    "                print(\"IoU:\", iou)  # Print IoU value\n",
    "                iou_values.append(iou)  # Optionally store IoU value\n",
    "            if iou >= iou_threshold:\n",
    "                true_positives += 1\n",
    "                false_negatives -= 1\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            false_positives += 1\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    return precision, recall, iou_values  # Return IoU values along with precision and recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "IoU Values: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Assume compute_iou and precision_recall_at_iou_threshold functions are defined as above\n",
    "\n",
    "# # Example data\n",
    "# predicted_boxes = [\n",
    "#     [0.1, 0.2, 0.5, 0.6],\n",
    "#     [0.15, 0.25, 0.55, 0.65]\n",
    "# ]\n",
    "# ground_truth_boxes = [\n",
    "#     [0.12, 0.22, 0.52, 0.62]\n",
    "# ]\n",
    "\n",
    "# Evaluate model\n",
    "precision, recall, iou_values = precision_recall_at_iou_threshold(output[1][6,0,:,:], targets['x_boxes_reshape'][6,0,:,:], iou_threshold=0.1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(\"IoU Values:\", iou_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate_model(model, dataset, iou_threshold=0.5):\n",
    "#     all_precisions = []\n",
    "#     all_recalls = []\n",
    "\n",
    "#     for images, labels in dataset:\n",
    "#         probabilities, boxes = model.predict(images)\n",
    "#         # Process model outputs here: convert probabilities to binary indicators, extract bounding boxes, etc.\n",
    "#         # This depends on your model output format and how you've decided to threshold/interpret probabilities\n",
    "\n",
    "#         for i in range(len(images)):\n",
    "#             pred_boxes = extract_boxes(boxes[i], probabilities[i])  # You'll need to implement this based on your model output structure\n",
    "#             gt_boxes = labels['x_boxes_reshape'][i].numpy()  # Adjust based on actual label structure\n",
    "#             precision, recall = precision_recall_at_iou_threshold(pred_boxes, gt_boxes, iou_threshold=iou_threshold)\n",
    "#             all_precisions.append(precision)\n",
    "#             all_recalls.append(recall)\n",
    "\n",
    "#     # Compute overall metrics\n",
    "#     mean_precision = np.mean(all_precisions)\n",
    "#     mean_recall = np.mean(all_recalls)\n",
    "#     print(f\"Mean Precision: {mean_precision}, Mean Recall: {mean_recall}\")\n",
    "\n",
    "# def evaluate_model(model, dataset, iou_threshold=0.5):\n",
    "#     all_precisions = []\n",
    "#     all_recalls = []\n",
    "\n",
    "#     for images, labels in dataset:\n",
    "#         probabilities, boxes = model.predict(images)\n",
    "#         for i in range(len(images)):\n",
    "#             # Corrected call to extract_boxes\n",
    "#             pred_boxes = extract_boxes((probabilities['x_prob_reshape'][i], boxes[i]), probability_threshold=0.5)\n",
    "            \n",
    "#             # Extract ground truth bounding boxes\n",
    "#             gt_boxes = extract_ground_truth_boxes(labels['x_boxes_reshape'][i].numpy())\n",
    "            \n",
    "#             # Evaluate precision and recall for the current set of predictions and ground truth\n",
    "#             precision, recall = precision_recall_at_iou_threshold(pred_boxes, gt_boxes, iou_threshold=iou_threshold)\n",
    "#             all_precisions.append(precision)\n",
    "#             all_recalls.append(recall)\n",
    "\n",
    "#     # Compute overall metrics\n",
    "#     mean_precision = np.mean(all_precisions)\n",
    "#     mean_recall = np.mean(all_recalls)\n",
    "#     print(f\"Mean Precision: {mean_precision}, Mean Recall: {mean_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "\n",
    "\n",
    "# dataset = dataset.batch(10000)\n",
    "# inputs,targets = next(iter(dataset))\n",
    "# output = loaded_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_labels = targets['x_boxes_reshape']\n",
    "# predicted_labels = output[1]\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# # Example: Flatten arrays if they are in matrix form\n",
    "# true_labels_flat = true_labels\n",
    "# predicted_labels_flat = predicted_labels\n",
    "\n",
    "# # Precision, Recall, and F1 Score\n",
    "# precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "# recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "# f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "# print(f\"Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((images_np,{'x_prob_reshape':probabilities,'x_boxes_reshape':boxes_np}))\n",
    "\n",
    "# # # Assuming dataset has 10,000 examples and we want an 80/20 split\n",
    "# # total_items = 10000\n",
    "# # train_size = int(total_items * 0.6)\n",
    "# # # val_size = total_items - train_size\n",
    "\n",
    "# # # Splitting the dataset\n",
    "# # train_dataset = dataset.take(train_size)\n",
    "# # # val_dataset = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "# # # train_dataset = train_dataset.shuffle(buffer_size=train_size,reshuffle_each_iteration=True)\n",
    "# # train_dataset = train_dataset.batch(6000)\n",
    "# # inputs,targets = next(iter(train_dataset))\n",
    "# dataset = dataset.batch(10000)\n",
    "# inputs,targets = next(iter(dataset))\n",
    "# output = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your test dataset is structured similarly to your training dataset\n",
    "# with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "#     test_images = hdf.get('images')\n",
    "#     test_boxes = hdf.get('boxes')\n",
    "#     test_images = np.array(test_images[:999])\n",
    "#     test_boxes = np.array(test_boxes[:999])\n",
    "\n",
    "# # Normalizing test data\n",
    "# test_images_normalized = (test_images + 1e-9) / 9.26\n",
    "# test_normalized_boxes = test_boxes / [1, 64, 64, 64, 64]\n",
    "\n",
    "# # Preparing test dataset\n",
    "# test_probabilities = np.array(test_normalized_boxes[:, :, :-4])\n",
    "# test_probabilities = tf.expand_dims(test_probabilities, axis=1)\n",
    "# test_boxes_np = np.array(test_normalized_boxes[:, :, 1:])\n",
    "# test_boxes_np = tf.expand_dims(test_boxes_np, axis=1)\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images_normalized, {'x_prob_reshape': test_probabilities, 'x_boxes_reshape': test_boxes_np}))\n",
    "# test_dataset = test_dataset.batch(128)  # Use the same batch size as in training\n",
    "\n",
    "# # Evaluate the model\n",
    "# # Evaluate the model on the test dataset\n",
    "# eval_results = model.evaluate(test_dataset)\n",
    "\n",
    "# # Printing evaluation results\n",
    "# print(\"Evaluation results (Overall loss, loss per output, and metrics per output):\")\n",
    "# for metric_name, metric_value in zip(model.metrics_names, eval_results):\n",
    "#     print(f\"{metric_name}: {metric_value}\")\n",
    "\n",
    "# # Since the model has multiple outputs and potentially multiple metrics, you may have a structure like this:\n",
    "# # [overall_loss, loss_x_prob_reshape, loss_x_boxes_reshape, metric1_x_prob_reshape, metric1_x_boxes_reshape, ...]\n",
    "\n",
    "# # If you specifically want to print out just the overall test loss and a particular metric, such as the accuracy for the probability predictions, you can do so by accessing the appropriate indices. \n",
    "# # Note: Adjust the indices based on your actual model's metrics.\n",
    "# print(f\"Overall Test Loss: {eval_results[0]}\")\n",
    "# print(f\"Accuracy for probability predictions (x_prob_reshape): {eval_results[3]}\") # Assuming the accuracy for `x_prob_reshape` is the first metric after the losses.\n",
    "\n",
    "\n",
    "# # Generate predictions for a subset of the test dataset\n",
    "# # for test_images_batch, _ in test_dataset.take(1):  # Taking a single batch\n",
    "# #     predictions = model.predict(test_images_batch)\n",
    "# #     probabilities_pred, boxes_pred = predictions\n",
    "\n",
    "# #     # Visualizing predictions for the first few images in the batch\n",
    "# #     num_images_to_display = 5\n",
    "# #     fig, axs = plt.subplots(1, num_images_to_display, figsize=(20, 5))\n",
    "# #     for i in range(num_images_to_display):\n",
    "# #         axs[i].imshow(test_images_batch[i].squeeze(), cmap='gray')  # Assuming grayscale images\n",
    "# #         # Here you could also overlay the true and predicted bounding boxes\n",
    "# #         # This part is left as an exercise since it depends on your specific needs and data format\n",
    "# #     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_bounding_boxes(image, probability_vector, bounding_box_coordinates, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Visualizes bounding boxes on an image based on a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - probability_vector: A 1D tensor representing the probabilities associated with bounding boxes.\n",
    "    - bounding_box_coordinates: A 2D tensor representing bounding box coordinates.\n",
    "    - threshold: Probability threshold for visualization.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with bounding boxes).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    prob_vector_np = probability_vector\n",
    "    bbox_coordinates_np = bounding_box_coordinates\n",
    "   # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(\"Bounding Box Visualization\")\n",
    "\n",
    "    # Plot bounding boxes based on probability threshold\n",
    "    for i in range(len(prob_vector_np)):\n",
    "        prob = prob_vector_np[i]\n",
    "        bbox = bbox_coordinates_np[i]\n",
    "        if prob > threshold:\n",
    "            # Denormalize bounding box coordinates if necessary\n",
    "            denormalized_bbox = bbox  # Modify if normalization was applied during training\n",
    "            y1, x1, y2, x2 = denormalized_bbox\n",
    "            plt.plot([x1, x2, x2, x1, x1],[y1, y1, y2, y2, y1],\n",
    "                     \n",
    "                     color='r', linewidth=2, label='Bounding Box')\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "t = np.random.randint(0,400)\n",
    "\n",
    "\n",
    "visualize_bounding_boxes(tf.convert_to_tensor(inputs[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(output[1][t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "visualize_bounding_boxes(tf.convert_to_tensor(image_normalized[t]), probabilities.numpy()[t].squeeze(), tf.convert_to_tensor(boxes_np[t,0,:,:])*[64,64,64,64]) ##myprediction\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
