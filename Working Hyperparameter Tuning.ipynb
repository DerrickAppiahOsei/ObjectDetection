{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 11:35:47.933634: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-01 11:35:47.965740: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 11:35:47.965766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 11:35:47.966634: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 11:35:47.972021: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 11:35:48.623928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-01 11:35:49.940665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22135 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "\n",
    "# Configure Keras to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (1480004830.py, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 85\u001b[0;36m\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Ensure wandb is installed: pip install wandb\n",
    "# Initialize your W&B project before running the script\n",
    "\n",
    "# Dataset loading and preparation\n",
    "def load_and_prepare_dataset(batch_size):\n",
    "    with h5py.File('TrainingData5zeroes.h5', 'r') as hdf:\n",
    "        images = np.array(hdf.get('images'))\n",
    "        boxes = np.array(hdf.get('boxes'))\n",
    "\n",
    "    image_normalized = (images + 1e-9) / 9.26\n",
    "    normalized_boxes = boxes / [1, 64, 64, 64, 64]\n",
    "\n",
    "    images_np = image_normalized\n",
    "    probabilities = np.array(normalized_boxes[:, :, :-4])\n",
    "    probabilities = tf.expand_dims(probabilities, axis=1)\n",
    "    boxes_np = np.array(normalized_boxes[:, :, 1:])\n",
    "    boxes_np = tf.expand_dims(boxes_np, axis=1)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_boxes_reshape': boxes_np}))\n",
    "    dataset = dataset.shuffle(buffer_size=10000).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Model building\n",
    "def build_model():\n",
    "    input_shape = (64, 64, 1)\n",
    "    num_classes = 280\n",
    "    num_coordinates = 4\n",
    "\n",
    "    x_input = layers.Input(shape=input_shape)\n",
    "    #Layer 1\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 2\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 3\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    #Layer 4\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    #Layer 5\n",
    "    x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.BatchNormalization()(x) \n",
    "    \n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "    x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "    x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "    x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "    model = models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "    return model\n",
    "\n",
    "# Optimizer selection\n",
    "def select_optimizer(optimizer_name, learning_rate):\n",
    "    if optimizer_name == 'adam':\n",
    "        return optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        return optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer specified.\")\n",
    "\n",
    "# Training function with sweep\n",
    "def train_with_sweep():\n",
    "    # config_defaults = {\n",
    "    #     'batch_size': 32,\n",
    "    #     'epochs': 10,\n",
    "    #     'optimizer': 'adam',\n",
    "    #     'learning_rate': 0.001\n",
    "    }\n",
    "    # with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        dataset = load_and_prepare_dataset(config.batch_size)\n",
    "        model = build_model()\n",
    "\n",
    "        optimizer = select_optimizer(config.optimizer, config.learning_rate)\n",
    "        model.compile(optimizer=optimizer, \n",
    "                      loss={'x_prob_reshape': 'binary_crossentropy', 'x_boxes_reshape': 'mean_squared_error'}, \n",
    "                      metrics={'x_prob_reshape': 'accuracy'})\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(dataset, epochs=config.epochs, callbacks=[wandb.keras.WandbCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam', 'sgd']\n",
    "        },\n",
    "    'fc_layer_size': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "    'dropout': {\n",
    "          'values': [0.3, 0.4, 0.5]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 1}\n",
    "    })\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'loss', 'goal': 'minimize'},\n",
       " 'parameters': {'optimizer': {'values': ['adam', 'sgd']},\n",
       "  'fc_layer_size': {'values': [128, 256, 512]},\n",
       "  'dropout': {'values': [0.3, 0.4, 0.5]},\n",
       "  'epochs': {'value': 1},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 0, 'max': 0.1},\n",
       "  'batch_size': {'distribution': 'q_log_uniform_values',\n",
       "   'q': 8,\n",
       "   'min': 32,\n",
       "   'max': 256}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: y8wizmg0\n",
      "Sweep URL: https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7zdmv06h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06493151529635642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mderrickappiahosei\u001b[0m (\u001b[33malphanium\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_113853-7zdmv06h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/7zdmv06h/workspace' target=\"_blank\">earnest-sweep-1</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/7zdmv06h/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/7zdmv06h/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 11:38:57.884303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22135 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "2024-04-01 11:39:00.006913: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-01 11:39:00.094740: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-01 11:39:01.291485: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-01 11:39:02.329775: I external/local_xla/xla/service/service.cc:168] XLA service 0x7e00ed13f640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-01 11:39:02.329817: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711985942.396777  116435 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/66 [=>............................] - ETA: 5s - loss: 0.7936 - x_prob_reshape_loss: 0.6025 - x_boxes_reshape_loss: 0.1910 - x_prob_reshape_accuracy: 0.6838WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0439s). Check your callbacks.\n",
      "66/66 [==============================] - 27s 206ms/step - loss: 0.3675 - x_prob_reshape_loss: 0.2506 - x_boxes_reshape_loss: 0.1169 - x_prob_reshape_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.36748</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.11692</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.90005</td></tr><tr><td>x_prob_reshape_loss</td><td>0.25057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-1</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/7zdmv06h/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/7zdmv06h/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_113853-7zdmv06h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8puziy8v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08803421471082627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_113934-8puziy8v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8puziy8v/workspace' target=\"_blank\">northern-sweep-2</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8puziy8v/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8puziy8v/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/139 [>.............................] - ETA: 6s - loss: 0.7943 - x_prob_reshape_loss: 0.5993 - x_boxes_reshape_loss: 0.1950 - x_prob_reshape_accuracy: 0.6861WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0222s vs `on_train_batch_end` time: 0.0241s). Check your callbacks.\n",
      "139/139 [==============================] - 18s 79ms/step - loss: 0.2523 - x_prob_reshape_loss: 0.1708 - x_boxes_reshape_loss: 0.0815 - x_prob_reshape_accuracy: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.25227</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.08148</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.93366</td></tr><tr><td>x_prob_reshape_loss</td><td>0.17079</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-2</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8puziy8v/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8puziy8v/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_113934-8puziy8v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aoam44zz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.016980419134374126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114005-aoam44zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/aoam44zz/workspace' target=\"_blank\">eager-sweep-3</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/aoam44zz/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/aoam44zz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/79 [=>............................] - ETA: 5s - loss: 0.8633 - x_prob_reshape_loss: 0.6711 - x_boxes_reshape_loss: 0.1922 - x_prob_reshape_accuracy: 0.6154WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0293s vs `on_train_batch_end` time: 0.0350s). Check your callbacks.\n",
      "79/79 [==============================] - 17s 93ms/step - loss: 0.5003 - x_prob_reshape_loss: 0.3471 - x_boxes_reshape_loss: 0.1531 - x_prob_reshape_accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.50026</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.15315</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.86144</td></tr><tr><td>x_prob_reshape_loss</td><td>0.34712</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-3</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/aoam44zz/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/aoam44zz/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114005-aoam44zz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8pzrzym0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004676496519068174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114036-8pzrzym0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8pzrzym0/workspace' target=\"_blank\">serene-sweep-4</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8pzrzym0/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8pzrzym0/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 11:40:43.452430: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/97 [>.............................] - ETA: 5s - loss: 0.5745 - x_prob_reshape_loss: 0.4461 - x_boxes_reshape_loss: 0.1284 - x_prob_reshape_accuracy: 0.7856WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0279s vs `on_train_batch_end` time: 0.0307s). Check your callbacks.\n",
      "97/97 [==============================] - 17s 62ms/step - loss: 0.1964 - x_prob_reshape_loss: 0.1300 - x_boxes_reshape_loss: 0.0664 - x_prob_reshape_accuracy: 0.9427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.19636</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.06635</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.94273</td></tr><tr><td>x_prob_reshape_loss</td><td>0.13001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-sweep-4</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8pzrzym0/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8pzrzym0/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114036-8pzrzym0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ybyje3v9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09995131764049162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114106-ybyje3v9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/ybyje3v9/workspace' target=\"_blank\">sunny-sweep-5</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/ybyje3v9/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/ybyje3v9/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/84 [=>............................] - ETA: 5s - loss: 2.2348 - x_prob_reshape_loss: 2.0401 - x_boxes_reshape_loss: 0.1947 - x_prob_reshape_accuracy: 0.7216WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0292s vs `on_train_batch_end` time: 0.0336s). Check your callbacks.\n",
      "84/84 [==============================] - 11s 105ms/step - loss: 0.8486 - x_prob_reshape_loss: 0.7304 - x_boxes_reshape_loss: 0.1182 - x_prob_reshape_accuracy: 0.7515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.8486</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.11822</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.75148</td></tr><tr><td>x_prob_reshape_loss</td><td>0.73039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-sweep-5</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/ybyje3v9/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/ybyje3v9/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114106-ybyje3v9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1rhwvaow with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00510938517648396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114132-1rhwvaow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/1rhwvaow/workspace' target=\"_blank\">crimson-sweep-6</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/1rhwvaow/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/1rhwvaow/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/105 [>.............................] - ETA: 5s - loss: 0.6230 - x_prob_reshape_loss: 0.4882 - x_boxes_reshape_loss: 0.1348 - x_prob_reshape_accuracy: 0.7678WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0253s vs `on_train_batch_end` time: 0.0270s). Check your callbacks.\n",
      "105/105 [==============================] - 15s 56ms/step - loss: 0.2079 - x_prob_reshape_loss: 0.1370 - x_boxes_reshape_loss: 0.0709 - x_prob_reshape_accuracy: 0.9402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.2079</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.07087</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.94022</td></tr><tr><td>x_prob_reshape_loss</td><td>0.13703</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-6</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/1rhwvaow/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/1rhwvaow/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114132-1rhwvaow/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: izgi9n5f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09850021225296518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114202-izgi9n5f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/izgi9n5f/workspace' target=\"_blank\">firm-sweep-7</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/izgi9n5f/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/izgi9n5f/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/74 [=>............................] - ETA: 5s - loss: 0.7785 - x_prob_reshape_loss: 0.5852 - x_boxes_reshape_loss: 0.1933 - x_prob_reshape_accuracy: 0.7012WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0311s vs `on_train_batch_end` time: 0.0403s). Check your callbacks.\n",
      "74/74 [==============================] - 16s 79ms/step - loss: 0.3067 - x_prob_reshape_loss: 0.2081 - x_boxes_reshape_loss: 0.0986 - x_prob_reshape_accuracy: 0.9181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.3067</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.09864</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.91814</td></tr><tr><td>x_prob_reshape_loss</td><td>0.20806</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-sweep-7</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/izgi9n5f/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/izgi9n5f/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114202-izgi9n5f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8xpx77on with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09084981082198074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114232-8xpx77on</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8xpx77on/workspace' target=\"_blank\">bumbling-sweep-8</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8xpx77on/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8xpx77on/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 11s 33ms/step - loss: 0.6364 - x_prob_reshape_loss: 0.5351 - x_boxes_reshape_loss: 0.1013 - x_prob_reshape_accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.63644</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.10133</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.77332</td></tr><tr><td>x_prob_reshape_loss</td><td>0.5351</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-8</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8xpx77on/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/8xpx77on/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114232-8xpx77on/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gfkmsx2e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0833747905303685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114258-gfkmsx2e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/gfkmsx2e/workspace' target=\"_blank\">still-sweep-9</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/gfkmsx2e/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/gfkmsx2e/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/66 [=>............................] - ETA: 5s - loss: 2.2710 - x_prob_reshape_loss: 2.0573 - x_boxes_reshape_loss: 0.2138 - x_prob_reshape_accuracy: 0.6966WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0372s vs `on_train_batch_end` time: 0.0421s). Check your callbacks.\n",
      "66/66 [==============================] - 8s 83ms/step - loss: 0.8925 - x_prob_reshape_loss: 0.7778 - x_boxes_reshape_loss: 0.1146 - x_prob_reshape_accuracy: 0.7566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.89247</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.11464</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.75663</td></tr><tr><td>x_prob_reshape_loss</td><td>0.77783</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-sweep-9</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/gfkmsx2e/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/gfkmsx2e/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114258-gfkmsx2e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0xk3mat6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005222724154517866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/m3-learning/wandb/run-20240401_114318-0xk3mat6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/0xk3mat6/workspace' target=\"_blank\">toasty-sweep-10</a></strong> to <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/sweeps/y8wizmg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/0xk3mat6/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/0xk3mat6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/114 [>.............................] - ETA: 5s - loss: 0.9233 - x_prob_reshape_loss: 0.7253 - x_boxes_reshape_loss: 0.1980 - x_prob_reshape_accuracy: 0.5588WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0232s vs `on_train_batch_end` time: 0.0263s). Check your callbacks.\n",
      "114/114 [==============================] - 18s 89ms/step - loss: 0.5866 - x_prob_reshape_loss: 0.4140 - x_boxes_reshape_loss: 0.1727 - x_prob_reshape_accuracy: 0.8256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>x_boxes_reshape_loss</td><td>▁</td></tr><tr><td>x_prob_reshape_accuracy</td><td>▁</td></tr><tr><td>x_prob_reshape_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.58664</td></tr><tr><td>x_boxes_reshape_loss</td><td>0.17265</td></tr><tr><td>x_prob_reshape_accuracy</td><td>0.82563</td></tr><tr><td>x_prob_reshape_loss</td><td>0.41399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-sweep-10</strong> at: <a href='https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/0xk3mat6/workspace' target=\"_blank\">https://wandb.ai/alphanium/Working%20Hyperparameter%20Tuning/runs/0xk3mat6/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_114318-0xk3mat6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Working Hyperparameter Tuning\")\n",
    "wandb.agent(sweep_id, train_with_sweep, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
