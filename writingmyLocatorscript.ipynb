{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 13:05:19.368983: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 13:05:19.401600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 13:05:19.401630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 13:05:19.402588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 13:05:19.408110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 13:05:20.105645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def connected_components_tf(image, num_iterations=100):\n",
    "    if not tf.is_tensor(image):\n",
    "        raise TypeError(f\"Input type is not a tf.Tensor. Got: {type(image)}\")\n",
    "    \n",
    "    if not isinstance(num_iterations, int) or num_iterations < 1:\n",
    "        raise TypeError(\"Input num_iterations must be a positive integer.\")\n",
    "    \n",
    "    if len(image.shape) < 3 or image.shape[-3] != 1:\n",
    "        raise ValueError(f\"Input image shape must be (*, 1, H, W). Got: {image.shape}\")\n",
    "    \n",
    "    # Reshape image to 2D if it's more than 3D\n",
    "    shape = tf.shape(image)\n",
    "    image = tf.reshape(image, [-1, shape[-2], shape[-3]])\n",
    "    \n",
    "    # Create initial labels\n",
    "    B, H, W = image.shape\n",
    "    labels = tf.reshape(tf.range(B * H * W, dtype=image.dtype), [B, H, W])\n",
    "    mask = tf.equal(image, 1)\n",
    "    \n",
    "    # Initialize labels as zero where mask is False\n",
    "    labels = tf.where(mask, labels, tf.zeros_like(labels))\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Max pool current labels to simulate the dilation effect\n",
    "        labels = tf.expand_dims(labels, axis=3)  # Add a channel dimension\n",
    "        pooled_labels = tf.nn.max_pool2d(labels, ksize=3, strides=1, padding='SAME')\n",
    "        labels = tf.squeeze(pooled_labels, axis=[-1])  # Remove the channel dimension\n",
    "        labels = tf.where(mask, labels, tf.zeros_like(labels))\n",
    "    \n",
    "    return tf.reshape(labels, shape)\n",
    "\n",
    "# # Example usage\n",
    "# img = tf.random.uniform((2, 1, 4, 5), dtype=tf.float32)\n",
    "# img_labels = connected_components_tf(img, num_iterations=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stitch_windows_tf(windows, k, cropx, cropy):\n",
    "    # Example of adapting the stich_windows for TensorFlow\n",
    "    # Assumes 'windows' is a TensorFlow tensor\n",
    "    row0 = tf.concat([windows[0, 0][:-k, :-k]] +\n",
    "                     [win[:-k, k:-k] for win in windows[0, 1:-1]] +\n",
    "                     [windows[0, -1][:-k, k:]], axis=1)\n",
    "    rows = [row0]\n",
    "    for r in range(1, windows.shape[0] - 1):\n",
    "        rows.append(tf.concat([windows[r, 0][k:-k, :-k]] +\n",
    "                              [win[k:-k, k:-k] for win in windows[r, 1:-1]] +\n",
    "                              [windows[r, -1][k:-k, k:]], axis=1))\n",
    "    row_last = tf.concat([windows[-1, 0][k:, :-k]] +\n",
    "                         [win[k:, k:-k] for win in windows[-1, 1:-1]] +\n",
    "                         [windows[-1, -1][k:, k:]], axis=1)\n",
    "    final = tf.concat([row0] + rows[1:] + [row_last], axis=0)\n",
    "    final = final[:cropx, :cropy]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LocatorTF:\n",
    "    def __init__(self, fastrcnn_model, process_stride=64, method='max', dark_threshold=20,\n",
    "                 locating_model=None, mode='static', **kwargs):\n",
    "        self.fastrcnn_model = fastrcnn_model\n",
    "        # self.device = device\n",
    "        self.process_stride = process_stride\n",
    "        self.method = method\n",
    "        self.dark_threshold = dark_threshold\n",
    "        self.locating_model = locating_model\n",
    "        self.mode = mode\n",
    "        self.p_list = kwargs.get('p_list', [8, 6, 1.5, 1, 50])\n",
    "        self.meanADU = kwargs.get('meanADU', 241.0)\n",
    "        self.dynamic_thres = kwargs.get('dynamic_thres', True)\n",
    "        self.pretune_thresholding = kwargs.get('pretune_thresholding')\n",
    "\n",
    "    def model_tune(self, arr):\n",
    "        # Placeholder for model tuning logic\n",
    "        pass\n",
    "\n",
    "    def images_to_window_lists(self, inputs):\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        outputs = []\n",
    "        h, w = inputs.shape[1], inputs.shape[2]\n",
    "\n",
    "        if self.process_stride is None:\n",
    "            windows = tf.image.resize(inputs, [h * 2, w * 2], method='nearest')\n",
    "            outputs.extend(tf.reshape(windows, [-1, h * 2, w * 2, 1]))\n",
    "        else:\n",
    "            # Add padding if necessary\n",
    "            pad_height = (self.process_stride - h % self.process_stride) % self.process_stride\n",
    "            pad_width = (self.process_stride - w % self.process_stride) % self.process_stride\n",
    "            inputs_padded = tf.pad(inputs, [[0, 0], [0, pad_height], [0, pad_width], [0, 0]])\n",
    "\n",
    "            # Extract patches\n",
    "            windows = tf.image.extract_patches(\n",
    "                images=inputs_padded,\n",
    "                sizes=[1, self.process_stride, self.process_stride, 1],\n",
    "                strides=[1, self.process_stride, self.process_stride, 1],\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding='VALID'\n",
    "            )\n",
    "\n",
    "            # Reshape output for further processing\n",
    "            batch_size, num_rows, num_cols, _ = windows.shape\n",
    "            outputs.extend(tf.reshape(windows, [batch_size * num_rows * num_cols, self.process_stride, self.process_stride, 1]))\n",
    "        return outputs\n",
    "\n",
    "    def predict_sequence(self, inputs):\n",
    "        # self.fastrcnn_model.training = False\n",
    "        counted_list = []\n",
    "        eventsize_all = []\n",
    "\n",
    "        image_cell_list = self.images_to_window_lists(inputs)\n",
    "        for i, image_cell in enumerate(image_cell_list):\n",
    "            if self.mode == 'dynamic_window':\n",
    "                self.model_tune(image_cell)\n",
    "\n",
    "            image_cell = (image_cell - tf.reduce_min(image_cell)) / (tf.reduce_max(image_cell) - tf.reduce_min(image_cell))\n",
    "            boxes = self.fastrcnn_model.predict(image_cell)  # Assume 'predict' is implemented to handle TensorFlow inputs\n",
    "            filtered_boxes = self.filter_boxes(boxes)  # Assuming a method to filter boxes based on certain criteria\n",
    "            filtered, _, eventsize = self.locate(image_cell, filtered_boxes)\n",
    "            counted_list.append(filtered)\n",
    "            eventsize_all.extend(eventsize)\n",
    "\n",
    "        # Stitch windows and return final image\n",
    "        counted_images = stitch_windows_tf(tf.concat(counted_list, axis=0), k=3, cropx=inputs.shape[1], cropy=inputs.shape[2])\n",
    "        return counted_images, eventsize_all\n",
    "\n",
    "    def locate(self, image_array, boxes):\n",
    "        width = 10\n",
    "        filtered = tf.zeros_like(image_array)\n",
    "        coor = []\n",
    "        eventsize = []\n",
    "\n",
    "        for box in boxes:\n",
    "            y1, x1, y2, x2 = tf.cast(box, tf.int32)\n",
    "            xarea = image_array[y1:y2+1, x1:x2+1]\n",
    "\n",
    "            patch = tf.pad(xarea, [[1, 1], [1, 1]], mode='CONSTANT', constant_values=0)\n",
    "            patch = tf.image.resize(patch, [width, width], method='nearest')\n",
    "\n",
    "            if self.method == 'max':\n",
    "                idx = tf.argmax(tf.reshape(patch, [-1]))\n",
    "                model_y, model_x = divmod(idx, width)\n",
    "            elif self.method in ['com', 'binary_com']:\n",
    "                if self.method == 'binary_com':\n",
    "                    patch = tf.cast(patch >= 30, tf.float32)\n",
    "                coords = tf.stack(tf.meshgrid(tf.range(width), tf.range(width), indexing='ij'), axis=-1)\n",
    "                total_mass = tf.reduce_sum(patch)\n",
    "                center_mass = tf.reduce_sum(patch[:, :, tf.newaxis] * tf.cast(coords, tf.float32), axis=[0, 1])\n",
    "                model_y, model_x = tf.unstack(tf.round(center_mass / total_mass))\n",
    "\n",
    "            cx = model_y + y1 - 1\n",
    "            cy = model_x + x1 - 1\n",
    "\n",
    "            if cx >= 0 and cy >= 0 and cx < image_array.shape[0] and cy < image_array.shape[1]:\n",
    "                filtered[cx, cy] += 1\n",
    "                coor.append((cx, cy))\n",
    "                eventsize.append(tf.reduce_sum(patch > 20))\n",
    "\n",
    "        return filtered, coor, eventsize\n",
    "\n",
    "    def filter_boxes(self, boxes):\n",
    "        # Example filter that selects boxes based on area criteria\n",
    "        return [box for box in boxes if 0 < (box[2] - box[0]) * (box[3] - box[1]) < 900]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import center_of_mass, maximum_position\n",
    "from scipy.ndimage import label, find_objects\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "\n",
    "##########################################################################################################################\n",
    "### Counting methods ###\n",
    "# Below list six different counting methods, primaryly use connected component labeling(CCL) to find the clusters, \n",
    "# and assign the entry position to max intensity pixel, or center of mass, or center of mass after binarization, or random.\n",
    "# the last one, fastrcnn_predict, is using the ML model, instead of CCL.\n",
    "# all methods return the 256x256 counted image and coords array of shape(num, 2)\n",
    "\n",
    "\n",
    "def cca(img):\n",
    "  '''\n",
    "  only returns the stats from cca\n",
    "  '''\n",
    "  thresh = np.array(img > 20).astype('int8')\n",
    "  output = cv2.connectedComponentsWithStatsWithAlgorithm(thresh, 8, cv2.CV_32S, 0) \n",
    "  (_, _, stats, centroids) = output\n",
    "  return stats\n",
    "\n",
    "\n",
    "def counting_filter_binary_com(image, threshold=20, structure = np.ones((3,3))):\n",
    "    image_binary = image > threshold  # more readable\n",
    "    all_labels, num = label(image_binary, structure = np.ones((3,3)))  # get blobs\n",
    "    m=np.ones(shape=all_labels.shape)\n",
    "    obj = center_of_mass(m, all_labels, range(1,num))\n",
    "    obj = np.rint(obj).astype(int)\n",
    "    x = np.zeros(shape=np.shape(image))\n",
    "    x[obj[:,0],obj[:,1]]=1\n",
    "    return x, obj\n",
    "\n",
    "\n",
    "def counting_filter_com(image, threshold=20, structure = np.ones((3,3))):\n",
    "    image_binary = image > threshold  # more readable\n",
    "    all_labels, num = label(image_binary, structure = np.ones((3,3)))  # get blobs\n",
    "    # m=np.ones(shape=all_labels.shape)\n",
    "    obj = center_of_mass(image, all_labels, range(1,num))\n",
    "    obj = np.rint(obj).astype(int)\n",
    "    x = np.zeros(shape=np.shape(image))\n",
    "    x[obj[:,0],obj[:,1]]=1\n",
    "    return x, obj\n",
    "\n",
    "\n",
    "def counting_filter_max(image, threshold=20, structure = np.ones((3,3))):\n",
    "    eventsize = []\n",
    "    image_binary = image > threshold  # more readable\n",
    "    all_labels, num = label(image_binary, structure = np.ones((3,3)))  # get blobs\n",
    "    m=np.ones(shape=all_labels.shape)\n",
    "    obj = maximum_position(image, all_labels, range(1,num))\n",
    "    obj = np.rint(obj).astype(int)\n",
    "    x = np.zeros(shape=np.shape(image))\n",
    "    x[obj[:,0],obj[:,1]]=1\n",
    "    for i in np.arange(num)[1:]:\n",
    "      eventsize.append(np.where(all_labels==i)[0].shape[0])\n",
    "    return x, obj, np.array(eventsize).astype('int')\n",
    "\n",
    "\n",
    "def counting_filter_random(image, threshold=20, structure = np.ones((3,3))):\n",
    "    image_binary = image > threshold  # more readable\n",
    "    all_labels, num = label(image_binary, structure = np.ones((3,3)))  # get blobs\n",
    "    obj = find_objects(all_labels)\n",
    "    coords = []\n",
    "    for i in range(len(obj)):\n",
    "      coords.append((np.random.randint(obj[i][0].start,obj[i][0].stop),\n",
    "                    np.random.randint(obj[i][1].start,obj[i][1].stop)))\n",
    "    coords = np.array(coords)\n",
    "    x = np.zeros(shape=np.shape(image))\n",
    "    x[coords[:,0], coords[:,1]] = 1\n",
    "    return x, coords\n",
    "\n",
    "\n",
    "def fastrcnn_predict(model, arr, process_stride, mode, **kwargs):\n",
    "  from CountingNN.locator import Locator\n",
    "  x = arr[None, ...]\n",
    "  # device =  torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "  counting = LocatorTF(model, process_stride, 'max', 30, None, mode, meanADU = kwargs.get('meanADU'), \n",
    "                     p_list=kwargs.get('p_list'), dynamic_thres = kwargs.get('dynamic_thres'), pretune_thresholding = kwargs.get('pretune_thresholding'))\n",
    "  filtered, event_sizes =  counting.predict_sequence(x)\n",
    "  filtered = filtered[0]\n",
    "  all_coords = []\n",
    "  for value in range(1, 1 + filtered.max()):\n",
    "      coords = np.array(np.where(filtered==value))        \n",
    "      all_coords.append([coords]*value)\n",
    "  all_coords = np.hstack(np.array(all_coords)[0]).T\n",
    "\n",
    "  return filtered, all_coords, event_sizes\n",
    "\n",
    "##########################################################################################################################\n",
    "### Evaluation metrics calculation ###\n",
    "\n",
    "def pos_deviation(coords, truth, threshold):\n",
    "    \"\"\"\n",
    "    Cal the root mean square error between detected electron incident positions and the ground truth positions in units of pixels.\n",
    "    \"\"\"\n",
    "    # elements in pair 1 need to be no less than pair 2 \n",
    "    distances = []\n",
    "    if len(coords):\n",
    "      assigment,distances = pairwise_distances_argmin_min(coords, truth)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def general_evaluation(file, algorithm, repeat, savepath, **kwargs):\n",
    "  '''\n",
    "  This function is for calculating the scores for each data file, Stack***.npz together. \n",
    "  Arguments\n",
    "  -----------\n",
    "  file: the validation data file. e.g., my Stack000.npz contains images with sparsity 0~0.002, array X is the input images, \n",
    "  it has the shape of [N, M, 256, 256], N different sparsity ranging from sparsitymin(0) to sparsitymax(0.002), M copies of each same sparsity.\n",
    "  Then Stack001.npz contains images with sparsity 0.002~0.004, and so on. \n",
    "\n",
    "  algorithm: run evaluation of one counting algorithm, string of the function name defined above.\n",
    "\n",
    "  repeat: set the number of images with identical sparsity in each data file to be used.  \n",
    "  '''\n",
    "  data = np.load(file)\n",
    "\n",
    "  X = data['X'][:,:repeat]\n",
    "  y = data['y'][:,:repeat]\n",
    "  print('Max pixel value in ground truth:', y.max())\n",
    "  # creat blank arrays to store the score values, which has the same first two dimension as X. \n",
    "  dce = np.zeros(X.shape[:2]) # dce: simple detector conversion efficiency,  the ratio of input and detected electron counts\n",
    "  mae = np.zeros(X.shape[:2]) # mae: mean absolute error, the absolute error of electron counts averaged over all pixels in a single image\n",
    "  nume = np.zeros(X.shape[:2]) # number of actrual electrons in the image\n",
    "  recall = np.zeros(X.shape[:2]) # recall, true positive / (true positives + false negtives)\n",
    "  precision = np.zeros(X.shape[:2]) # precision, true positive / (true positives + false positives)\n",
    "  filtered =  np.zeros(X.shape) # i.e. the counted image\n",
    "\n",
    "  # saving the coordinate, position deviation and event size for each detected electron event in the image, \n",
    "  # so need to create an array of objects, and the object is a list\n",
    "  coords = [ [0] * X.shape[1] ] * X.shape[0]\n",
    "  deviations = [ [0] * X.shape[1] ] * X.shape[0]\n",
    "  eventsizes = [ [0] * X.shape[1] ] * X.shape[0]\n",
    "  coords = np.array(coords, dtype=object)\n",
    "  deviations = np.array(deviations, dtype=object)\n",
    "  eventsizes = np.array(eventsizes, dtype=object)\n",
    "  save_e_size = True\n",
    "\n",
    "\n",
    "  # Now go through the NxM images to get the scores\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "          \n",
    "      if algorithm =='fastrcnn_predict':\n",
    "        model = kwargs.get('model')\n",
    "        method = kwargs.get('method')\n",
    "        stride = kwargs.get('stride')\n",
    "        mode = kwargs.get('mode')\n",
    "        meanADU = kwargs.get('meanADU')\n",
    "        p_list = kwargs.get('p_list')\n",
    "        dynamic_thres = kwargs.get('dynamic_thres')\n",
    "        pretune_thresholding = kwargs.get('pretune_thresholding')\n",
    "        # by using the \"eval\", the long string has been read as a line of code, and it runs the algorithm function\n",
    "        res = eval(algorithm +\"(model, X[i][j], stride, mode, meanADU=meanADU, p_list=p_list, dynamic_thres = dynamic_thres,pretune_thresholding = pretune_thresholding )\")\n",
    "        filtered[i,j] = res[0]\n",
    "        coords[i][j] = res[1]\n",
    "        # if the algorithm returns eventsize, set to save it.\n",
    "        try:\n",
    "          eventsizes[i][j] = res[2]\n",
    "        except:\n",
    "          save_e_size = False\n",
    "\n",
    "      else: \n",
    "        res = eval(algorithm + \"(X[i][j])\")\n",
    "        filtered[i,j] = res[0]\n",
    "        coords[i][j] = res[1]\n",
    "        try:\n",
    "          eventsizes[i][j] = res[2]\n",
    "        except:\n",
    "          save_e_size = False\n",
    "      \n",
    "      # Get all the ground truth coordinates of electron events\n",
    "      # For a pixel value 2 for example, indicating 2 electrons here, so we need to add its coordinate twice. \n",
    "      truth = []\n",
    "      for value in range(1, 1+int(y[i,j].max())):\n",
    "        truth_ = np.array(np.where(y[i,j]==value))        \n",
    "        truth.append([truth_]*value)\n",
    "      truth = np.hstack(np.array(truth)[0]).T\n",
    "\n",
    "      total_pixel = filtered[i,j].shape[0] * filtered[i,j].shape[1]\n",
    "      mae[i,j] = np.sum(np.abs(filtered[i,j]-y[i,j]))/total_pixel\n",
    "      dce[i,j] = np.sum(filtered[i,j])/np.sum(y[i,j])\n",
    "      nume[i,j] = np.sum(y[i,j])\n",
    "\n",
    "      tp = 0 \n",
    "      # count how many electron events are well identified, i.e., count the true positives\n",
    "      for n, value in enumerate(filtered[i,j].ravel()):\n",
    "\n",
    "        if (value != 0) & (y[i,j].ravel()[n] != 0):\n",
    "          tp = tp + np.min((value, y[i,j].ravel()[n])) # multi-class considered\n",
    "\n",
    "      recall[i,j] = tp/nume[i,j]\n",
    "      precision[i,j] = tp/np.sum(filtered[i,j])\n",
    "\n",
    "      deviations[i][j] = pos_deviation(coords[i][j], truth, 6)\n",
    "      dce[i,j] = len(deviations[i][j])/np.sum(y[i,j])\n",
    "\n",
    "  path = savepath + file[-12:-4]\n",
    "  if save_e_size:\n",
    "    np.savez(path+'_result.npz', coordinates = coords, result = filtered, mae = mae, dce = dce, nume = nume, \n",
    "    recall = recall, precision = precision, deviations = deviations, eventsizes = eventsizes)\n",
    "  else:\n",
    "    np.savez(path+'_result.npz', coordinates = coords, result = filtered, mae = mae, dce = dce, nume = nume, \n",
    "    recall = recall, precision = precision, deviations = deviations)\n",
    "    \n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    \"\"\"\n",
    "    Create a directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "    - directory_path (str): Path of the directory to be created.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        try:\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"Directory '{directory_path}' created successfully.\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating directory '{directory_path}': {e}\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 13:05:33.119962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21968 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64,64,1)\n",
    "num_classes = 280\n",
    "num_coordinates = 4\n",
    "\n",
    "x_input = layers.Input(shape=input_shape)\n",
    "#Layer 1\n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 2\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 3\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "#Layer 4\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "#Layer 5\n",
    "x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# Probability output\n",
    "x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "x_prob_reshape = layers.Reshape((-1, num_classes, 1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "# Bounding box output\n",
    "x_boxes = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_boxes')(x)\n",
    "x_boxes_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_boxes_reshape')(x_boxes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(x_input, [x_prob_reshape, x_boxes_reshape])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5) \n",
    "model.compile(optimizer= optimizer, loss= {'x_prob_reshape': tf.keras.losses.BinaryCrossentropy(), 'x_boxes_reshape':tf.keras.losses.MeanSquaredError()}, metrics=['accuracy'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 57 variables. \n"
     ]
    }
   ],
   "source": [
    "u= model.load_weights(\"/home/m3-learning/Documents/Research Data/Derrick's Object Detection/Models/M11overfittedmodel4variant.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 64, 64, 64)           640       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_10[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 64)           256       ['max_pooling2d_5[0][0]']     \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 128)          73856     ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 128)          147584    ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 256)          295168    ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 256)          590080    ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 512)          1180160   ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 512)          0         ['conv2d_16[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 512)          2359808   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 512)            0         ['conv2d_17[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 8, 8, 512)            2359808   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 512)            0         ['conv2d_18[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 4, 4, 256)            3277056   ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 2, 2, 256)            0         ['conv2d_19[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 2, 2, 256)            1024      ['max_pooling2d_9[0][0]']     \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1024)                 0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " x_prob (Dense)              (None, 280)                  287000    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " x_boxes (Dense)             (None, 1120)                 1148000   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " x_prob_reshape (Reshape)    (None, 1, 280, 1)            0         ['x_prob[0][0]']              \n",
      "                                                                                                  \n",
      " x_boxes_reshape (Reshape)   (None, 1, 280, 4)            0         ['x_boxes[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11757368 (44.85 MB)\n",
      "Trainable params: 11756728 (44.85 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/m3-learning/Documents/myML/ValidationResults/' already exists.\n",
      "Max pixel value in ground truth: 2.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path):\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pattern\u001b[38;5;241m.\u001b[39mmatch(file):\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mgeneral_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msavepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdynamic_window\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#meanADU = 1007\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWorked on \u001b[39m\u001b[38;5;124m'\u001b[39m, file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m     16\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[4], line 169\u001b[0m, in \u001b[0;36mgeneral_evaluation\u001b[0;34m(file, algorithm, repeat, savepath, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     save_e_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 169\u001b[0m   res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[43malgorithm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(X[i][j])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m)\n\u001b[1;32m    170\u001b[0m   filtered[i,j] \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    171\u001b[0m   coords[i][j] \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "savepath = '/home/m3-learning/Documents/myML/ValidationResults/'\n",
    "path = '/home/m3-learning/Documents/myML/ValidationData-20231107T163458Z-001/ValidationData/'\n",
    "\n",
    "create_directory_if_not_exists(savepath)\n",
    "\n",
    "# Regular expression pattern to match files starting with 'Stack' and ending with '.npz'\n",
    "pattern = re.compile(r'^Stack.*\\.npz$')\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "for file in os.listdir(path):\n",
    "  if pattern.match(file):\n",
    "    general_evaluation(path + file, algorithm = None, repeat = 1, savepath = savepath, model = u,\n",
    "                      method = 'max',  mode = 'dynamic_window', stride = 64) #meanADU = 1007\n",
    "    print('\\nWorked on ', file, 'cost', \" %s seconds.\" % (time.time() - start_time))\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class LocatorTF:\n",
    "#     def __init__(self, fastrcnn_model, process_stride=64, method='max', dark_threshold=20, locating_model=None,\n",
    "#                  mode='static', **kwargs):\n",
    "#         self.fastrcnn_model = fastrcnn_model\n",
    "#         self.mode = mode\n",
    "#         self.process_stride = process_stride\n",
    "#         self.method = method\n",
    "#         self.locating_model = locating_model\n",
    "#         self.dark_threshold = dark_threshold\n",
    "#         self.p_list = kwargs.get('p_list', [8, 6, 1.5, 1, 50])\n",
    "#         self.meanADU = kwargs.get('meanADU', 241.0)\n",
    "#         self.dynamic_thres = kwargs.get('dynamic_thres', True)\n",
    "#         self.pretune_thresholding = kwargs.get('pretune_thresholding')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     def model_tune(self, arr):\n",
    "#         meanADU = self.meanADU * 4  # mean ADU * upsample_factor^2\n",
    "#         offset = 0\n",
    "#         limit = int(tf.reduce_sum(arr) / meanADU + offset)\n",
    "#         arr_t = tf.cast(arr[None, None, ...] > 30, tf.float32)\n",
    "        \n",
    "#         # Assuming a custom implementation for connected components that returns a count\n",
    "#         # since TensorFlow doesn't have a direct equivalent.\n",
    "#         limit_cca = connected_components_tf(arr_t, num_iterations=10)\n",
    "#         limit = max(limit_cca, limit)\n",
    "#         limit = max(limit, 1)\n",
    "\n",
    "#         self.fastrcnn_model.rpn._pre_nms_top_n = {'training': limit * self.p_list[0], 'testing': limit * self.p_list[0]}\n",
    "#         self.fastrcnn_model.rpn._post_nms_top_n = {'training': limit * self.p_list[1],\n",
    "#                                                    'testing': limit * self.p_list[1]}\n",
    "#         self.fastrcnn_model.roi_heads.detections_per_img = int(limit * self.p_list[2])\n",
    "#         # self.fastrcnn_model.roi_heads.score_thresh = self.p_list[3] / limit if limit < self.p_list[4] else 0\n",
    "#         self.fastrcnn_model.roi_heads.score_thresh = self.p_list[3] / limit\n",
    "\n",
    "#         self.fastrcnn_model.roi_heads.nms_thresh = 0.02  # smaller, delete more detections\n",
    "\n",
    "#         if limit > (0.005 * arr.shape[0] * arr.shape[1]) and self.dynamic_thres:  # 0.002 is minimum for model13\n",
    "#             self.dark_threshold = 0  # for image that not quite sparse, lift the pre-thresholding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
